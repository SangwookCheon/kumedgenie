import streamlit as st
import os
import glob
import warnings
import pandas as pd
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredMarkdownLoader,
    UnstructuredWordDocumentLoader,
    TextLoader
)
from langchain_core.prompts import PromptTemplate
from langchain_community.callbacks import get_openai_callback

# KUMEDGENIE 

#custom functions
from visit_counter import get_visit_count, update_visit_count, get_last_visit, update_last_visit  # Import visit tracking

# Load environment variables
load_dotenv()

# HYPERPARAMETERS
n_search_kwargs = 3

# Suppress warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Set API Key
openai_api_key = os.getenv("OPENAI_API_KEY")
prompt_text = os.getenv("PROMPT_TEMPLATE")

if not openai_api_key:
    st.error("âŒ OPENAI_API_KEY is missing. Please set it in `.env` or Streamlit Secrets.")
else:
    os.environ["OPENAI_API_KEY"] = openai_api_key

# Initialize session state for retrieved chunks
if "retrieved_chunks" not in st.session_state:
    st.session_state["retrieved_chunks"] = []


# Visit Counter implementation
visit_count = update_visit_count()
last_visit = get_last_visit()
update_last_visit()

# Streamlit UI
st.title("ğŸ¯ğŸ” ê³ ë ¤ëŒ€ ì˜ê³¼ëŒ€í•™ ì •ë³´ ì§€ë‹ˆ")
st.write("ì§€ë‹ˆëŠ” ì‹ ì…ìƒ ìˆ˜ê°• ì‹ ì²­ ì •ë³´ì™€ ìœ ìš©í•œ íŒ, ê³ ë ¤ëŒ€í•™êµ ì˜ê³¼ëŒ€í•™ í•™ì¹™(íœ´Â·ë³µí•™, ì´ì¤‘ ì „ê³µ, ì¥í•™ìƒ ê¸°ì¤€ ë“±)ì— ëŒ€í•œ ê¶ê¸ˆì¦ì„ í•´ê²°í•´ ë“œë¦½ë‹ˆë‹¤!")

# Define document storage folder
DOC_FOLDER = "temp_rec"
FAISS_INDEX_PATH = "faiss_index"

# Define supported file loaders
FILE_LOADERS = {
    "pdf": PyPDFLoader,
    "md": UnstructuredMarkdownLoader,
    "txt": TextLoader,
    "docx": UnstructuredWordDocumentLoader,
}

# Check if FAISS index exists
if os.path.exists(FAISS_INDEX_PATH):
    st.success("âœ… ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ë°”ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”!")
    vectorstore = FAISS.load_local(FAISS_INDEX_PATH, OpenAIEmbeddings(), allow_dangerous_deserialization=True)
    retriever = vectorstore.as_retriever(search_kwargs={"k": n_search_kwargs})
else:
    st.warning("ğŸ“‚ ë¬¸ì„œë¥¼ ì²˜ìŒ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.")

    all_files = []
    for ext in FILE_LOADERS.keys():
        all_files.extend(glob.glob(os.path.join(DOC_FOLDER, f"*.{ext}")))

    if not all_files:
        st.error("âŒ ì§€ì›ë˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
    else:
        all_documents = []
        for file_path in all_files:
            ext = file_path.split(".")[-1].lower()
            if ext in FILE_LOADERS:
                loader = FILE_LOADERS[ext](file_path)
                documents = loader.load()

                # Store file source metadata for each document
                for doc in documents:
                    doc.metadata["source"] = os.path.basename(file_path)

                all_documents.extend(documents)

        # Split documents
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,
                                                       chunk_overlap=200,
                                                       separators=["\n# ", "\n## ", "\n### "])
        splits = text_splitter.split_documents(all_documents)

        # Embed and store in FAISS
        vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())
        vectorstore.save_local(FAISS_INDEX_PATH)  
        retriever = vectorstore.as_retriever(search_kwargs={"k": n_search_kwargs})

        st.success("âœ… ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸í•˜ì„¸ìš”.")

# Custom RAG prompt
custom_prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=prompt_text
)

# Set up LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# Define function to retrieve and format context
def retrieve_and_format_docs(query):
    # with get_openai_callback() as cb:
    #     retrieved_docs = retriever.invoke(query)
    #     st.write(cb)

    retrieved_docs = retriever.invoke(query)
    retrieved_chunks_display = []

    for doc in retrieved_docs:
        source = doc.metadata.get("source", "Unknown Source")
        text = f"{doc.page_content}\n\nğŸ“Œ ì¶œì²˜: {source}"
        retrieved_chunks_display.append(text)

    # Store retrieved chunks in session state
    st.session_state["retrieved_chunks"] = retrieved_chunks_display  

    return "\n\n---\n\n".join(retrieved_chunks_display)  # Separate retrieved chunks

# Define RAG chain
rag_chain = (
    {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
    | custom_prompt
    | llm
    | StrOutputParser()
)

# User input field
with st.form(key="question_form"):
    query = st.text_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì§ˆë¬¸ì´ êµ¬ì²´ì ì¼ìˆ˜ë¡ ë”ìš± ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤):")
    submit_button = st.form_submit_button("Submit")

if submit_button:
    if query:
        # Retrieve context BEFORE invoking RAG
        formatted_context = retrieve_and_format_docs(query)

        # Invoke RAG with retrieved context
        response = rag_chain.invoke({"context": formatted_context, "question": query})

        # Show answer
        st.write("### ì§€ë‹ˆì˜ ë‹µë³€:")
        st.write(response)

        # Add an expandable section for the retrieved chunks
        with st.expander("ğŸ“Œ ì¶œì²˜ í‘œì‹œ"):
            if "retrieved_chunks" in st.session_state and st.session_state["retrieved_chunks"]:
                st.write("### ğŸ“Œ ì°¸ê³ í•œ ë¬¸ì„œ ë‚´ìš©:")
                for chunk in st.session_state["retrieved_chunks"]:
                    st.write(chunk)  # Show first 500 characters for readability
                    st.write("\n")
            else:
                st.write("âŒ ì°¸ê³ í•œ ë¬¸ì„œ ì¡°ê°ì´ ì—†ìŠµë‹ˆë‹¤.")

    else:
        st.warning("ì§ˆë¬¸ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")
    

st.markdown(
f"""
<hr style="margin-top: 50px;">
<p style="text-align: center; font-size: 14px;">
    Made with â¤ï¸ by Wookie at &lt;/+/&gt;
</p>
""",
unsafe_allow_html=True
)

#    ë°©ë¬¸ íšŸìˆ˜: {visit_count}íšŒ | ë§ˆì§€ë§‰ ë°©ë¬¸: {last_visit} <br>